{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, token, freq):\n",
    "        self.token = token\n",
    "        self.freq = freq\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.idx = None\n",
    "        \n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq\n",
    "    \n",
    "    def __gt__(self, other):\n",
    "        return self.freq > other.freq\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if(other == None):\n",
    "            return False\n",
    "        if(not isinstance(other, Node)):\n",
    "            return False\n",
    "        return self.freq == other.freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuffmanTree:\n",
    "    def __init__(self):\n",
    "        self.heap = []\n",
    "        self.codes = {}\n",
    "        self.reverse_mapping = {}\n",
    "        self.root = None\n",
    "        \n",
    "    def make_heap(self, frequency):\n",
    "        for key in frequency:\n",
    "            node = Node(key, frequency[key])\n",
    "            heapq.heappush(self.heap, node)\n",
    "            \n",
    "    def merge_nodes(self):\n",
    "        while(len(self.heap)>1):\n",
    "            node1 = heapq.heappop(self.heap)\n",
    "            node2 = heapq.heappop(self.heap)\n",
    "            \n",
    "            merged = Node(None, node1.freq + node2.freq)\n",
    "            merged.left = node1\n",
    "            merged.right = node2\n",
    "            heapq.heappush(self.heap, merged)\n",
    "            \n",
    "    def make_codes_helper(self, root, current_code):\n",
    "        if(root==None):\n",
    "            return\n",
    "        if(root.token != None):\n",
    "            self.codes[root.token] = current_code\n",
    "            self.reverse_mapping[current_code] = root.token\n",
    "            return\n",
    "        \n",
    "        self.make_codes_helper(root.left, current_code + \"0\")\n",
    "        self.make_codes_helper(root.right, current_code + \"1\")\n",
    "        \n",
    "    def make_codes(self):\n",
    "        root = heapq.heappop(self.heap)\n",
    "        self.root = root\n",
    "        current_code = \"\"\n",
    "        self.make_codes_helper(root, current_code)\n",
    "        \n",
    "    def assign_ids(self):\n",
    "        root = self.root\n",
    "        queue = []\n",
    "        queue.append(root)\n",
    "        idx = 0\n",
    "        \n",
    "        while(len(queue)):\n",
    "            root = queue.pop(0)\n",
    "            \n",
    "            if root.left:\n",
    "                queue.append(root.left)\n",
    "            if root.right:\n",
    "                queue.append(root.right)\n",
    "                \n",
    "            if (root.left or root.right):\n",
    "                root.idx = idx \n",
    "                idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_huffman_tree(vocab):\n",
    "    ht = HuffmanTree()\n",
    "    ht.make_heap(vocab)\n",
    "    ht.merge_nodes()\n",
    "    ht.make_codes()\n",
    "    ht.assign_ids()\n",
    "    \n",
    "    return ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pickle.load(open(\"vocab.p\", \"rb\"))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "hs_weights = torch.randn((vocab_size-1, 300), dtype=torch.float, requires_grad=True)\n",
    "word_embeddings = torch.randn((vocab_size, 300), dtype=torch.float, requires_grad=True)\n",
    "\n",
    "ht = make_huffman_tree(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelevanceModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab):\n",
    "        vocab_size = len(vocab)\n",
    "        \n",
    "        hs_weights = Variable(torch.randn((vocab_size-1, 300), dtype=torch.float, requires_grad=True))\n",
    "        word_embeddings = Variable(torch.randn((vocab_size, 300), dtype=torch.float, requires_grad=True))\n",
    "        \n",
    "        self.query_embedding = nn.Linear(self.vocab_size, 300, bias=False)\n",
    "        \n",
    "    def forward(self, q, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_range(c1, c2):\n",
    "    \"\"\"Generates the characters from `c1` to `c2`, inclusive.\"\"\"\n",
    "    for c in range(ord(c1), ord(c2)+1):\n",
    "        yield chr(c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = {}\n",
    "voc['a'] = 641\n",
    "voc['b'] = 589\n",
    "voc['c'] = 938\n",
    "voc['d'] = 312\n",
    "voc['e'] = 254\n",
    "voc['f'] = 932\n",
    "voc['g'] = 0\n",
    "voc['h'] = 714"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = make_huffman_tree(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': '00',\n",
       " 'c': '01',\n",
       " 'g': '10000',\n",
       " 'e': '10001',\n",
       " 'd': '1001',\n",
       " 'b': '101',\n",
       " 'a': '110',\n",
       " 'h': '111'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 641, 'b': 589, 'c': 938, 'd': 312, 'e': 254, 'f': 932, 'g': 0, 'h': 714}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tensors = {}\n",
    "\n",
    "for k,v in ht.codes.items():\n",
    "    path = []\n",
    "    for c in v:\n",
    "        if c=='0':\n",
    "            path.append(1)\n",
    "        else:\n",
    "            path.append(-1)\n",
    "    path_tensors[k] = torch.tensor(path, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor([1., 1.]),\n",
       " 'c': tensor([ 1., -1.]),\n",
       " 'g': tensor([-1.,  1.,  1.,  1.,  1.]),\n",
       " 'e': tensor([-1.,  1.,  1.,  1., -1.]),\n",
       " 'd': tensor([-1.,  1.,  1., -1.]),\n",
       " 'b': tensor([-1.,  1., -1.]),\n",
       " 'a': tensor([-1., -1.,  1.]),\n",
       " 'h': tensor([-1., -1., -1.])}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectors = {}\n",
    "\n",
    "for k,v in ht.codes.items():\n",
    "    root = ht.root\n",
    "    sel = []\n",
    "    sel.append(root.idx)\n",
    "    \n",
    "    for c in v[:-1]:\n",
    "        if c=='0':\n",
    "            root = root.left\n",
    "        else:\n",
    "            root = root.right\n",
    "        sel.append(root.idx)\n",
    "    selectors[k] = torch.tensor(sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor([0, 1]),\n",
       " 'c': tensor([0, 1]),\n",
       " 'g': tensor([0, 2, 3, 5, 6]),\n",
       " 'e': tensor([0, 2, 3, 5, 6]),\n",
       " 'd': tensor([0, 2, 3, 5]),\n",
       " 'b': tensor([0, 2, 3]),\n",
       " 'a': tensor([0, 2, 4]),\n",
       " 'h': tensor([0, 2, 4])}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s 0\n",
      "1 2\n",
      "1 4\n"
     ]
    }
   ],
   "source": [
    "root = ht.root\n",
    "\n",
    "v = ht.codes['a']\n",
    "print('s', root.idx)\n",
    "for c in v[:-1]:\n",
    "    if c=='0':\n",
    "        root = root.left\n",
    "    else:\n",
    "        root = root.right\n",
    "    print(c, root.idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "we = torch.randn((len(voc)-1, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.randn(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = we[selectors['a']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul = torch.matmul(m1, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-21.2404,  -8.4863,   4.7103])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "prods = mul * path_tensors['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.stack((torch.tensor([0, 1]), torch.tensor([0, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = list(selectors.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [i.unsqueeze(0) for i in l1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [torch.tensor([0, 1]),\n",
    " torch.tensor([0, 1]),\n",
    " torch.tensor([0, 2, 3, 5, 6]),\n",
    " torch.tensor([0, 2, 3, 5, 6]),\n",
    " torch.tensor([0, 2, 3, 5]),\n",
    " torch.tensor([0, 2, 3]),\n",
    " torch.tensor([0, 2, 4]),\n",
    " torch.tensor([0, 2, 4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3 = torch.tensor([i.shape for i in l1])\n",
    "l3 = tuple(l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2]),\n",
       " tensor([2]),\n",
       " tensor([5]),\n",
       " tensor([5]),\n",
       " tensor([4]),\n",
       " tensor([3]),\n",
       " tensor([3]),\n",
       " tensor([3]))"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.cat(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = W[t1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 300])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = torch.split(m1, l3, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 300])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(m2, dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = torch.cat(tuple(path_tensors.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,\n",
       "        -1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1.])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "m21 = torch.cat(m2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 300])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m21.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.randn(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([300]), torch.Size([27, 300]))"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape, m21.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ -8.1478, -21.9214]),\n",
       " tensor([-8.1478, 21.9214]),\n",
       " tensor([  8.1478,  33.1918,  -7.2199, -17.2290,   6.6762]),\n",
       " tensor([  8.1478,  33.1918,  -7.2199, -17.2290,  -6.6762]),\n",
       " tensor([ 8.1478, 33.1918, -7.2199, 17.2290]),\n",
       " tensor([ 8.1478, 33.1918,  7.2199]),\n",
       " tensor([  8.1478, -33.1918,  24.0853]),\n",
       " tensor([  8.1478, -33.1918, -24.0853]))"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(torch.matmul(m21, h) * m3, l3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
